{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c4fa5c0",
   "metadata": {},
   "source": [
    "#### Dense Layer from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b96701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        \n",
    "        # Initialize weights and bias\n",
    "        self.W = self.add_weight((input_dim, output_dim))\n",
    "        self.b = self.add_weight((1, output_dim))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Forward propagate the inputs\n",
    "        z = tf.matmul(inputs, self.W) * self.b\n",
    "        \n",
    "        # Feed through a non-linear activation\n",
    "        output = tf.math.sigmoid(z)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1741217",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(units=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5578a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To define fully connected network or dense layer\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(6), #n\n",
    "    tf.keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32397ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary cross entropy loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b9703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared error loss\n",
    "loss = tf.reduce_mean(tf.square(tf.substract(y, predicted)))\n",
    "loss = tf.keras.losses.MSE(y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac13309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent Algorithm written in tensorflow\n",
    "weights = tf.Variable([tf.random.normal()])\n",
    "\n",
    "while True:\n",
    "    with tf.GradientTape() as g:\n",
    "        loss = compute_loss(weights)\n",
    "        gradient = g.gradient(loss, weights)\n",
    "    weights = weights - lr * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37dcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent algorithms\n",
    "SGD = tf.keras.optimizers.SGD\n",
    "Adam = tf.keras.optimizers.Adam\n",
    "Adadelta = tf.keras.optimizers.Adadelta\n",
    "Adagrad = tf.keras.optimizers.Adagrad\n",
    "RMSProp = tf.keras.optimizers.RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2838633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting it all together\n",
    "model = tf.keras.Sequential([..])\n",
    "\n",
    "#optimizer\n",
    "optimizer = tf.keras.optimizer.SGD()\n",
    "\n",
    "while True:\n",
    "    pediction = model(x)\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(y, prediction)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable.variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c98ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization - Dropout\n",
    "tf.keras.layers.Dropout(p=0.5) #drop 50% of activations in layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
